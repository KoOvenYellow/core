# llm_select_with_syndo.py
from openai import OpenAI
from dotenv import load_dotenv
import os
from irpc_jump import irpc_jump_probability
from irpc_evaluator import evaluate_irpc

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

client = OpenAI(api_key=api_key)

def generate_candidates(prompt, n=5):
    """
    GPTã«nå€‹ã®å‡ºåŠ›å€™è£œã‚’ç”Ÿæˆã•ã›ã‚‹ã€‚
    """
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "user", "content": prompt}
        ],
        n=n
    )
    return [choice.message.content for choice in response.choices]

def select_best_candidate(w1, candidates, sigma=2.0):
    """
    å„å€™è£œã«å¯¾ã™ã‚‹ã‚¸ãƒ£ãƒ³ãƒ—ç¢ºç‡ã‚’è¨ˆç®—ã—ã€æœ€ã‚‚é«˜ã„ã‚‚ã®ã‚’è¿”ã™ã€‚
    """
    best_p = -1
    best_w2 = ""
    for w2 in candidates:
        p = irpc_jump_probability(w1, w2, sigma)
        print(f"â†’ {w2}\n   P = {p:.4f}\n")
        if p > best_p:
            best_p = p
            best_w2 = w2
    return best_w2, best_p

if __name__ == "__main__":
    w1 = "ã“ã®ã‚µãƒ¼ãƒ“ã‚¹ã¯ã€ã‚ãªãŸã®ç”Ÿæ´»ã‚’æ ¹æœ¬ã‹ã‚‰å¤‰ãˆã‚‹é©æ–°çš„ãªã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã§ã™ã€‚"
    instruction = "ã“ã®æ–‡ã«ç¶šãé©åˆ‡ãªæ¬¡ã®ä¸€æ–‡ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚"

    print("=== IRPC scores for source sentence ===")
    w1_scores = evaluate_irpc(w1)
    for k, v in w1_scores.items():
        print(f"{k}: {v}")
    print("========================================\n")

    prompt = f"{w1}\n\n{instruction}"
    
    candidates = generate_candidates(prompt, n=5)
    best, score = select_best_candidate(w1, candidates)

    print("\nğŸ”¥ æœ€ã‚‚ã‚¸ãƒ£ãƒ³ãƒ—ç¢ºç‡ã®é«˜ã„å€™è£œï¼š")
    print(f"{best}\n(P = {score:.4f})")
